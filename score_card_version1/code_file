import  pandas as pd
from score_card_version1.split_bin import *
from score_card_version1.preprocessing import *
from score_card_version1.woe_information import *
from numpy import *
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve,auc
import matplotlib.pyplot as plt
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.ensemble import RandomForestClassifier

df=pd.read_excel('/Users/andpay/Documents/job/mode/score_card12.7.xlsx')
end_user_info=df.drop(['PARTYID','NAME','IDNO'],axis=1)
end_user_info.loc[end_user_info['CATEGORY']=='NM','CATEGORY']=0
end_user_info.loc[end_user_info['CATEGORY']=='M2','CATEGORY']=1


column=end_user_info.columns

'''根据空值情况筛选变量'''
use_list=[]
unuse_list=[]
for col in column:
    res=check_nullvalue(end_user_info,col)
    if res=='unuseable':
        unuse_list.append(col)
    else:
        use_list.append(col)

end_user_info=end_user_info.drop(unuse_list,axis=1)
new_column=end_user_info.columns

print(new_column)


'''把变量非空取值数小余5的归为分类变量,大于5的为连续变量'''
def category_var(dataframe):
    cat_list=[]
    con_list=[]
    column=dataframe.columns
    for var in column:
        value_list=dataframe[dataframe[var].notnull()][var].unique()
        if len(value_list)<=5:
            cat_list.append(var)
        else:
            con_list.append(var)

    return cat_list,con_list


cat_var,con_var=category_var(end_user_info)
cat_var.remove('CATEGORY')


'''分类变量处理'''
split_point_cat={}
split_cat_list = []
for var in cat_var:
    split_cat_list.append(var + '_cat')
    mid_dict={}
    if end_user_info[end_user_info[var].isnull()].shape[0] > 0:
        sort_value = sorted(list(end_user_info[end_user_info[var].notnull()][var].unique()))
        num = len(sort_value)
        for i in range(num):
            end_user_info.loc[(end_user_info[var] == sort_value[i]), var + '_cat'] = i
            mid_dict[i]=sort_value[i]

        end_user_info.loc[end_user_info[var].isnull(), var + '_cat'] = -1
        mid_dict[-1]='None'
        split_point_cat[var+'_cat']=mid_dict

    else:
        sort_value = sorted(list(end_user_info[end_user_info[var].notnull()][var].unique()))
        num = len(sort_value)
        for i in range(num):
            end_user_info.loc[(end_user_info[var] == sort_value[i]), var + '_cat'] = i
            mid_dict[i] = sort_value[i]

        split_point_cat[var + '_cat'] = mid_dict



'''连续变量进行等频分箱'''
split_point_freq={}
freq_var_list=[]
for var in con_var:
    freq_var_list.append(var+'_freq')
    split_point=basic_splitbin(end_user_info,var,numOfSplit=100) #先对数据进行等频分箱，分为100箱
    split_point_freq[var+'_freq']=split_point
    num=len(split_point)

    for i in range(num-1):
        before=split_point[i]
        after=split_point[i+1]
        #分箱后新设变量并重新赋值
        end_user_info.loc[(end_user_info[var] >= before) & (end_user_info[var] < after), var+'_freq'] = i

    end_user_info.loc[end_user_info[var] >= split_point[ num- 1], var + '_freq'] = i + 1  #最后一个分箱单独处理



'''等频变量卡方分箱'''
split_point_chi={}
chi_var_list=[]
monotone_list=[]
for var in freq_var_list:
    '''首次对数据分为5箱'''
    max_interval=5
    chi_var_list.append(var+'_bin')
    split_point=ChiMerge(end_user_info,var,'CATEGORY',max_interval=max_interval)  #卡方分箱，返回分箱分割点
    freq_value=split_point_freq[var] #引入等频分箱的数据分割点列表

    num = len(split_point)
    mid_dict = {}

    for i in range(num-1):
        before=split_point[i]
        after=split_point[i+1]
        min_value=freq_value[int(before)]
        max_value=freq_value[int(after)]
        bin_name=str(min_value) + '-' + str(max_value)
        #分箱后新设变量并重新赋值
        end_user_info.loc[(end_user_info[var] >= before) & (end_user_info[var] < after), var+'_bin'] = i
        mid_dict[i] =bin_name  #保存分箱范围到字典

    #最后一个分箱处理
    end_user_info.loc[end_user_info[var] >= split_point[num - 1], var+'_bin'] = i + 1
    specil_value=freq_value[int(split_point[num - 1])]
    mid_dict[i+1]=str(specil_value)+'-'+'inf'

    '''单调性检验,并做重新分箱处理'''
    mot=monotone(end_user_info,var+'_bin','CATEGORY') #单调性检验
    '''如果存在其他业务上可理解的非单调性变量（如年龄），需要在这里进行申明处理'''
    if var !='AGE_freq':
        while (not mot):
            max_interval -= 1
            split_point = ChiMerge(end_user_info, var, 'CATEGORY', max_interval=max_interval)
            num = len(split_point)
            mid_dict = {}

            for i in range(num - 1):
                before = split_point[i]
                after = split_point[i + 1]
                min_value = freq_value[int(before)]
                max_value = freq_value[int(after)]
                bin_name = str(min_value) + '-' + str(max_value)
                # 分箱后新设变量并重新赋值
                end_user_info.loc[(end_user_info[var] >= before) & (end_user_info[var] < after), var + '_bin'] = i
                mid_dict[i] = bin_name  # 保存分箱范围到字典

            end_user_info.loc[end_user_info[var] >= split_point[num - 1], var + '_bin'] = i + 1
            specil_value = freq_value[int(split_point[num - 1])]
            mid_dict[i + 1] = str(specil_value) + '-' + 'inf'

            mot = monotone(end_user_info, var+'_bin', 'CATEGORY')


    monotone_list.append([var+'_bin',mot])
    end_user_info.loc[end_user_info[var].isnull(),var+'_bin']=-1  #空值分箱单独处理
    mid_dict[-1]=['None']
    split_point_chi[var+'_bin']=mid_dict




monotone_df=pd.DataFrame(monotone_list,columns=['variable','monotone'])

combine_var_list=split_cat_list+chi_var_list
combine_point_dict=dict(split_point_cat,**split_point_chi)

'''woe和iv值计算'''
def get_woe_information(dataframe,variable_list,target_var):
    #求woe 和 infomation_value
    woe_dict={}
    information_list=[]
    for var in variable_list:
        woe,information_value=woe_informationvalue(dataframe,var,target_var)
        woe_dict[var]=woe
        information_list.append(information_value)


    #把所有值进行分解并封装成dataframe
    woe_list = []
    for var in variable_list:
        first_layer = woe_dict[var]
        for key in first_layer.keys():
            value = first_layer[key]['woe']
            count = first_layer[key]['count']
            woe_list.append([var, key, count,value])


    woe_df = pd.DataFrame(woe_list, columns=['variable', 'class','bad_count','woe'])
    information_df = pd.DataFrame({'variable': variable_list, 'information_value': information_list},
                                  columns=['variable', 'information_value'])

    return woe_df,information_df


woe_df,information_df=get_woe_information(end_user_info,split_point_chi,'CATEGORY')


excel_writer=pd.ExcelWriter('/Users/andpay/Documents/job/mode/xxx.xlsx',engine='xlsxwriter')
woe_df.to_excel(excel_writer,'woe',index=False)
information_df.to_excel(excel_writer,'informationvalue',index=False)
excel_writer.save()




end_var_list=['LASTDATE_freq_bin','ZMS_freq_bin','TD_SCORE_freq_bin','MONCOUNT_freq_bin','SUMAMT_freq_bin','COUNTS_freq_bin',
              'ACS_9_freq_bin','LOANTIMES_freq_bin','USC_9_freq_bin','FISTDATE_freq_bin','LOANAMT_freq_bin','CCNUM_freq_bin',
              'ACS_0_freq_bin','TLBALANCE_freq_bin','USC_0_freq_bin','TCL_freq_bin','TCLU_freq_bin','USERATE_freq_bin','AGE_freq_bin',
              'LG_cat']
'''

end_var_list=['LASTDATE_freq_bin','ZMS_freq_bin','TD_SCORE_freq_bin','MONCOUNT_freq_bin',
              'ACS_9_freq_bin',
              'TLBALANCE_freq_bin','TCL_freq_bin','USERATE_freq_bin','AGE_freq_bin',
              'LG_cat']
'''


'''随机森林挑选变量'''
'''
x=end_user_info[end_var_list]
y=end_user_info['CATEGORY']

RFC = RandomForestClassifier()
RFC.fit(x,y.astype(int))
features_rfc = end_var_list
featureImportance = {features_rfc[i]:RFC.feature_importances_[i] for i in range(len(features_rfc))} #变量重要性字典
featureImportanceSorted = sorted(featureImportance.items(),key=lambda x: x[1], reverse=True) #按照重要性排序
# we selecte the top 10 features
features_selection = [k[0] for k in featureImportanceSorted[:12]] #获取排名靠前的12个特征变量
'''


'''变量间相关性检验'''
var_relative=regression_analysis(end_user_info,end_var_list)
print(var_relative)


'''
多变量共线性检测：VIF（方差膨胀因子）
'''

matx = np.matrix(end_user_info[end_var_list])
for i in range(len(end_var_list)):
    vif=variance_inflation_factor(matx,i)
    print(end_var_list[i],vif)

def vif(matx):
    vif_list=[]
    for i in range(matx.shape[1]):
        vif=variance_inflation_factor(matx,i)
        vif_list.append(vif)


    max_vif=max(vif_list)

    return max_vif


'''
for i in range(len(end_var_list)):
    new_list = end_var_list.copy()
    print(new_list[i])
    new_list.remove(new_list[i])
    matx=np.matrix(end_user_info[new_list])
    vifs=vif(matx)

    print(vifs)
'''

locgit=LogisticRegression()
locgit.fit(end_user_info[end_var_list],end_user_info['CATEGORY'].astype(int))

intercept=locgit.intercept_
coef=locgit.coef_

mode_woe_df,mode_information_df=get_woe_information(end_user_info,end_var_list,'CATEGORY')


'''画ROC曲线'''
'''
probs=locgit.predict_proba(end_user_info[end_var_list])

fpr,tpr,threshold=roc_curve(end_user_info['CATEGORY'].astype(int),probs[:,1])
roc_auc = auc(fpr, tpr)

plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()
'''


#创建截距字典
coef_dict={}
for key,value in zip(end_var_list,coef[0]):
    coef_dict[key]=value


#把截距和斜率值放入woe的结果集中
for var,key in zip(mode_woe_df['variable'],mode_woe_df['class']):
    mode_woe_df.loc[(mode_woe_df['variable']==var)&(mode_woe_df['class']==key),'category']= combine_point_dict[var][key]

for var in mode_woe_df['variable'].unique():
    mode_woe_df.loc[(mode_woe_df['variable']==var),'coef']=coef_dict[var]

mode_woe_df['intercept']=intercept[0]


'''
excel_writer=pd.ExcelWriter('/Users/andpay/Documents/job/mode/xxx.xlsx',engine='xlsxwriter')
mode_woe_df.to_excel(excel_writer,'woe',index=False)
mode_information_df.to_excel(excel_writer,'informationvalue',index=False)
monotone_df.to_excel(excel_writer,'monotone',index=False)
excel_writer.save()
'''


